{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBNYA81XKwOi6B6I/rFKFO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhonKifle/Neural-Network/blob/main/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "train = pd.read_csv('/content/sample_data/mnist_train_small.csv')\n",
        "test = pd.read_csv('/content/sample_data/mnist_test.csv')\n",
        "train = train._append(train.head(1))\n",
        "test = test._append(test.head(1))\n",
        "print(test.shape)\n",
        "print(train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9PDY9TboiOu",
        "outputId": "80e549bf-010f-40a7-de09-11945fb72594"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 785)\n",
            "(20000, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see in above output, the dataset contain 784 bits (28X28) to represent a digits, and one label column to indicate the digit value. So, here we have to split the train set to (train , validation) with (80% , 20%) content of the train set."
      ],
      "metadata": {
        "id": "37Redo_2JMfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid = train.sample(frac=0.2)\n",
        "train = train.drop(valid.index)\n",
        "print(train.shape)\n",
        "print(valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY0Xlnn9JKvI",
        "outputId": "d4b0161f-34d1-45c1-8677-6cc62574daac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 785)\n",
            "(4000, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iLFEwoCgiu_",
        "outputId": "f8ae0930-535d-4001-c8e3-b30151565495"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.581  0.582  0.583  \\\n",
            "0  5  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "2  9  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "3  5  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "\n",
            "   0.584  0.585  0.586  0.587  0.588  0.589  0.590  \n",
            "0      0      0      0      0      0      0      0  \n",
            "2      0      0      0      0      0      0      0  \n",
            "3      0      0      0      0      0      0      0  \n",
            "\n",
            "[3 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the first column is a digit of 0-9, and the rest of 784 bits represent 28 X 28 MNIST image.\n"
      ],
      "metadata": {
        "id": "F6kdcTPlhBQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the output of one-hot encoding of the digit 5 is [0,0,0,0,0,1,0,0,0,0], and for 0 it is [1,0,0,0,0,0,0,0,0,0], similarly for the other digits they will contain '1' in their index positions."
      ],
      "metadata": {
        "id": "314bcEkdmYKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train.iloc[:,1:]\n",
        "train_y = train.iloc[:,0]"
      ],
      "metadata": {
        "id": "tWxZFA3mHTJT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_X.iloc[3].values.reshape(28,28))\n",
        "plt.title(\"digit - \"+str(train_y.iloc[3]))"
      ],
      "metadata": {
        "id": "U7pqOBsLnSJd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "ed3c0d7b-ae42-4b27-8355-b0e449eb8134"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'digit - 2')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_X/255\n",
        "train_X = [np.reshape(x, (784, 1)) for x in train_X.values]\n",
        "valid_X = valid.iloc[:,1:]\n",
        "valid_X = valid_X/255\n",
        "valid_X = [np.reshape(x, (784, 1)) for x in valid_X.values]\n",
        "valid_y = valid.iloc[:,0]\n",
        "test_X = test.iloc[:,1:]\n",
        "test_X = test_X/255\n",
        "test_y = test.iloc[:,0]"
      ],
      "metadata": {
        "id": "pu16FUdphR7e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to identify which digit, the output shall be defined in some form.\n",
        "1. We can have 4 bits to represent the binary value of 0-9\n",
        "2. Or more effiect we can use one-hot encode. For this demo we will use one-hot encode of the output label."
      ],
      "metadata": {
        "id": "QB-JCAbEiQ_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train.iloc[:,0]\n",
        "def one_hot(y):\n",
        "    one_hot_y = [np.zeros((10,1)) for a in y]\n",
        "    for i,e in zip(y,one_hot_y):\n",
        "      e[i] = 1\n",
        "    return one_hot_y\n",
        "train_y = train_y.to_numpy()\n",
        "train_y = one_hot(train_y)\n",
        "valid_y = valid_y.to_numpy()\n",
        "test_y = one_hot(test_y)"
      ],
      "metadata": {
        "id": "mfgJpQn4lSO0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above image is a 28 X 28 pixel image of a digit from the MNIST dataset. and as it is displayed its label is 5."
      ],
      "metadata": {
        "id": "OuH0mKmcrwe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us define our network:\n",
        "- 784 input neurons at the input layer\n",
        "- 30 neurons at the hidden layer ( depends on user choice)\n",
        "- 10 output neurons at the output layer"
      ],
      "metadata": {
        "id": "Lff9-OX_sjBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NN:\n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers\n",
        "    self.weights = []\n",
        "    self.biases = []\n",
        "    for i in range(len(layers)-1):\n",
        "      self.weights.append(np.random.randn(layers[i+1], layers[i]))\n",
        "      self.biases.append(np.random.randn(layers[i+1], 1))\n",
        "  def forward(self, X):\n",
        "    self.inputs = X\n",
        "    for i in range(len(self.layers)-1):\n",
        "      self.inputs = np.dot(self.weights[i], self.inputs) + self.biases[i]\n",
        "      self.inputs = self.sigmoid(self.inputs)\n",
        "    return self.inputs\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def sigmoid_derivative(self, x):\n",
        "    return self.sigmoid(x)*(1-self.sigmoid(x))\n",
        "  def SGD(self, X, y, epochs, batch_size, learning_rate, test_data=None):\n",
        "    for i in range(epochs):\n",
        "      for j in range(0, len(X), batch_size):\n",
        "        X_batch = X[j:j+batch_size]\n",
        "        y_batch = y[j:j+batch_size]\n",
        "        self.update_mini_batch(X_batch, y_batch, learning_rate)\n",
        "      if test_data:\n",
        "        err = self.evaluate(test_data)\n",
        "        print(\"Epoch {} : {} / {} ({}%)\".format(i,err,len(test_data[0]),100*err/len(test_data[0])))\n",
        "      else:\n",
        "        print(\"Epoch {} complete\".format(i))\n",
        "  def update_mini_batch(self, X, Y, learning_rate):\n",
        "    nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "    nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "    for x, y in zip(X, Y):\n",
        "      delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "      nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "      nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "    self.weights = [w-(learning_rate/len(X))*nw for w, nw in zip(self.weights, nabla_w)]\n",
        "    self.biases = [b-(learning_rate/len(X))*nb for b, nb in zip(self.biases, nabla_b)]\n",
        "  def backprop(self, x, y):\n",
        "\n",
        "    #forward pass: generate weighted sums and sigmoid outputs of each layer\n",
        "    nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "    nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "    activation = x\n",
        "    activations = [x]\n",
        "    zs = []\n",
        "    for b, w in zip(self.biases, self.weights):\n",
        "      z = np.dot(w, activation)+b\n",
        "      zs.append(z)\n",
        "      activation = self.sigmoid(z)\n",
        "      activations.append(activation)\n",
        "\n",
        "    #backward propagation\n",
        "    delta = self.cost(y, activations[-1]) * self.sigmoid_derivative(zs[-1])\n",
        "    nabla_b[-1] = delta\n",
        "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
        "    for l in range(2, len(self.layers)):\n",
        "      z = zs[-l]\n",
        "      sp = self.sigmoid_derivative(z)\n",
        "      delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
        "      nabla_b[-l] = delta\n",
        "      nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
        "    return (nabla_b, nabla_w)\n",
        "  def evaluate(self, test_data):\n",
        "    test_results = [(np.argmax(self.forward(x)), y) for (x, y) in zip(test_data[0], test_data[1])]\n",
        "    return sum(int(x == y) for (x, y) in test_results)\n",
        "  def cost(self, y, output):\n",
        "    return output - y\n",
        "net = NN([784,30,10])\n",
        "\n",
        "net.SGD(train_X, train_y, 30, 10, 3.0, test_data=(valid_X,valid_y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gblfbu-CehTu",
        "outputId": "43358691-ab65-41a5-feba-23c1bebb1939"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : 3136 / 4000 (78.4%)\n",
            "Epoch 1 : 3232 / 4000 (80.8%)\n",
            "Epoch 2 : 3544 / 4000 (88.6%)\n",
            "Epoch 3 : 3578 / 4000 (89.45%)\n",
            "Epoch 4 : 3599 / 4000 (89.975%)\n",
            "Epoch 5 : 3630 / 4000 (90.75%)\n",
            "Epoch 6 : 3651 / 4000 (91.275%)\n",
            "Epoch 7 : 3646 / 4000 (91.15%)\n",
            "Epoch 8 : 3650 / 4000 (91.25%)\n",
            "Epoch 9 : 3652 / 4000 (91.3%)\n",
            "Epoch 10 : 3664 / 4000 (91.6%)\n",
            "Epoch 11 : 3668 / 4000 (91.7%)\n",
            "Epoch 12 : 3673 / 4000 (91.825%)\n",
            "Epoch 13 : 3677 / 4000 (91.925%)\n",
            "Epoch 14 : 3683 / 4000 (92.075%)\n",
            "Epoch 15 : 3679 / 4000 (91.975%)\n",
            "Epoch 16 : 3678 / 4000 (91.95%)\n",
            "Epoch 17 : 3672 / 4000 (91.8%)\n",
            "Epoch 18 : 3670 / 4000 (91.75%)\n",
            "Epoch 19 : 3668 / 4000 (91.7%)\n",
            "Epoch 20 : 3680 / 4000 (92.0%)\n",
            "Epoch 21 : 3682 / 4000 (92.05%)\n",
            "Epoch 22 : 3679 / 4000 (91.975%)\n",
            "Epoch 23 : 3687 / 4000 (92.175%)\n",
            "Epoch 24 : 3680 / 4000 (92.0%)\n",
            "Epoch 25 : 3682 / 4000 (92.05%)\n",
            "Epoch 26 : 3684 / 4000 (92.1%)\n",
            "Epoch 27 : 3684 / 4000 (92.1%)\n",
            "Epoch 28 : 3681 / 4000 (92.025%)\n",
            "Epoch 29 : 3686 / 4000 (92.15%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30 Epochs bring a 92% accuracy in new data. This accuracy can be increased by setting randomness of entries in mini_batch. i.e. The mini batchs created were of the same content in every epoch. This can be further enhanced by shuffling the entire data set in every epoch, and creat a new and unique mini-batch contents. To help shuffle, you much join the (X,y) as a list and do the shuffling as follows:\n",
        "\n",
        " - random.shuffle(training_data)\n"
      ],
      "metadata": {
        "id": "4qcUaT6uFVao"
      }
    }
  ]
}