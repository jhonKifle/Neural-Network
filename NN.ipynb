{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5x5xOcZt+Dk5D1waHpRFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhonKifle/Neural-Network/blob/main/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "train = pd.read_csv('/content/sample_data/mnist_train_small.csv')\n",
        "test = pd.read_csv('/content/sample_data/mnist_test.csv')\n",
        "train = train._append(train.head(1))\n",
        "test = test._append(test.head(1))\n",
        "print(test.shape)\n",
        "print(train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9PDY9TboiOu",
        "outputId": "57d8b2fc-d653-44ad-f437-3e4b71a1fc5b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 785)\n",
            "(20000, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see in above output, the dataset contain 784 bits (28X28) to represent a digits, and one label column to indicate the digit value. So, here we have to split the train set to (train , validation) with (80% , 20%) content of the train set."
      ],
      "metadata": {
        "id": "37Redo_2JMfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid = train.sample(frac=0.2)\n",
        "train = train.drop(valid.index)\n",
        "print(train.shape)\n",
        "print(valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY0Xlnn9JKvI",
        "outputId": "6886fdaa-a258-4a1b-98e9-171416a45690"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 785)\n",
            "(4000, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iLFEwoCgiu_",
        "outputId": "47b6cb07-cbf5-4bae-e8e8-db9dade0977c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.581  0.582  0.583  \\\n",
            "0  5  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "1  7  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "2  9  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "\n",
            "   0.584  0.585  0.586  0.587  0.588  0.589  0.590  \n",
            "0      0      0      0      0      0      0      0  \n",
            "1      0      0      0      0      0      0      0  \n",
            "2      0      0      0      0      0      0      0  \n",
            "\n",
            "[3 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** that the first column is a digit of 0-9, and the rest of 784 bits represent 28 X 28 MNIST image.\n"
      ],
      "metadata": {
        "id": "F6kdcTPlhBQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train.iloc[:,1:]\n",
        "train_y = train.iloc[:,0]"
      ],
      "metadata": {
        "id": "tWxZFA3mHTJT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_X.iloc[3].values.reshape(28,28))\n",
        "plt.title(\"digit - \"+str(train_y.iloc[3]))"
      ],
      "metadata": {
        "id": "U7pqOBsLnSJd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "1afb33c9-e477-4e69-a229-07b6c6cad896"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'digit - 5')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above image is a 28 X 28 pixel image of a digit from the MNIST dataset. And as it is displayed its label is 5."
      ],
      "metadata": {
        "id": "OuH0mKmcrwe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_X/255\n",
        "train_X = [np.reshape(x, (784, 1)) for x in train_X.values]\n",
        "valid_X = valid.iloc[:,1:]\n",
        "valid_X = valid_X/255\n",
        "valid_X = [np.reshape(x, (784, 1)) for x in valid_X.values]\n",
        "valid_y = valid.iloc[:,0]\n",
        "test_X = test.iloc[:,1:]\n",
        "test_X = test_X/255\n",
        "test_y = test.iloc[:,0]"
      ],
      "metadata": {
        "id": "pu16FUdphR7e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to identify which digit, the output shall be defined in some form.\n",
        "1. We can have 4 bits to represent the binary value of 0-9\n",
        "2. Or more efficient we can use one-hot encode. For this demo we will use one-hot encode of the output label."
      ],
      "metadata": {
        "id": "QB-JCAbEiQ_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train.iloc[:,0]\n",
        "def one_hot(y):\n",
        "    one_hot_y = [np.zeros((10,1)) for a in y]\n",
        "    for i,e in zip(y,one_hot_y):\n",
        "      e[i] = 1\n",
        "    return one_hot_y\n",
        "train_y = train_y.to_numpy()\n",
        "train_y = one_hot(train_y)\n",
        "valid_y = valid_y.to_numpy()\n",
        "test_y = one_hot(test_y)\n",
        "print(train_y[0])"
      ],
      "metadata": {
        "id": "mfgJpQn4lSO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2f2a52-bcaf-4fcf-c426-497df356ca76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the output of one-hot encoding of the digit 5 is [0,0,0,0,0,1,0,0,0,0], and for 0 it is [1,0,0,0,0,0,0,0,0,0], similarly for the other digits they will contain '1' in their respective index positions."
      ],
      "metadata": {
        "id": "314bcEkdmYKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us define our network:\n",
        "- 784 input neurons at the input layer\n",
        "- 30 neurons at the hidden layer ( depends on user choice)\n",
        "- 10 output neurons at the output layer"
      ],
      "metadata": {
        "id": "Lff9-OX_sjBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NN:\n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers\n",
        "    self.weights = []\n",
        "    self.biases = []\n",
        "    for i in range(len(layers)-1):\n",
        "      self.weights.append(np.random.randn(layers[i+1], layers[i]))\n",
        "      self.biases.append(np.random.randn(layers[i+1], 1))\n",
        "  def forward(self, X):\n",
        "    self.inputs = X\n",
        "    for i in range(len(self.layers)-1):\n",
        "      self.inputs = np.dot(self.weights[i], self.inputs) + self.biases[i]\n",
        "      self.inputs = self.sigmoid(self.inputs)\n",
        "    return self.inputs\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def sigmoid_derivative(self, x):\n",
        "    return self.sigmoid(x)*(1-self.sigmoid(x))\n",
        "  def SGD(self, X, y, epochs, batch_size, learning_rate, test_data=None):\n",
        "    for i in range(epochs):\n",
        "      for j in range(0, len(X), batch_size):\n",
        "        X_batch = X[j:j+batch_size]\n",
        "        y_batch = y[j:j+batch_size]\n",
        "        self.update_mini_batch(X_batch, y_batch, learning_rate)\n",
        "      if test_data:\n",
        "        err = self.evaluate(test_data)\n",
        "        print(\"Epoch {} : {} / {} ({}%)\".format(i,err,len(test_data[0]),100*err/len(test_data[0])))\n",
        "      else:\n",
        "        print(\"Epoch {} complete\".format(i))\n",
        "  def update_mini_batch(self, X, Y, learning_rate):\n",
        "    nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "    nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "    for x, y in zip(X, Y):\n",
        "      delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "      nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "      nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "    self.weights = [w-(learning_rate/len(X))*nw for w, nw in zip(self.weights, nabla_w)]\n",
        "    self.biases = [b-(learning_rate/len(X))*nb for b, nb in zip(self.biases, nabla_b)]\n",
        "  def backprop(self, x, y):\n",
        "\n",
        "    #forward pass: generate weighted sums and sigmoid outputs of each layer\n",
        "    nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "    nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "    activation = x\n",
        "    activations = [x]\n",
        "    zs = []\n",
        "    for b, w in zip(self.biases, self.weights):\n",
        "      z = np.dot(w, activation)+b\n",
        "      zs.append(z)\n",
        "      activation = self.sigmoid(z)\n",
        "      activations.append(activation)\n",
        "\n",
        "    #backward propagation\n",
        "    delta = self.cost(y, activations[-1]) * self.sigmoid_derivative(zs[-1])\n",
        "    nabla_b[-1] = delta\n",
        "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
        "    for l in range(2, len(self.layers)):\n",
        "      z = zs[-l]\n",
        "      sp = self.sigmoid_derivative(z)\n",
        "      delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
        "      nabla_b[-l] = delta\n",
        "      nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
        "    return (nabla_b, nabla_w)\n",
        "  def evaluate(self, test_data):\n",
        "    test_results = [(np.argmax(self.forward(x)), y) for (x, y) in zip(test_data[0], test_data[1])]\n",
        "    return sum(int(x == y) for (x, y) in test_results)\n",
        "  def cost(self, y, output):\n",
        "    return output - y\n",
        "net = NN([784,30,10])\n",
        "\n",
        "net.SGD(train_X, train_y, 30, 10, 3.0, test_data=(valid_X,valid_y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gblfbu-CehTu",
        "outputId": "7f794341-02ff-4060-cdc1-437a474a196e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : 3332 / 4000 (83.3%)\n",
            "Epoch 1 : 3532 / 4000 (88.3%)\n",
            "Epoch 2 : 3594 / 4000 (89.85%)\n",
            "Epoch 3 : 3630 / 4000 (90.75%)\n",
            "Epoch 4 : 3649 / 4000 (91.225%)\n",
            "Epoch 5 : 3654 / 4000 (91.35%)\n",
            "Epoch 6 : 3664 / 4000 (91.6%)\n",
            "Epoch 7 : 3674 / 4000 (91.85%)\n",
            "Epoch 8 : 3676 / 4000 (91.9%)\n",
            "Epoch 9 : 3681 / 4000 (92.025%)\n",
            "Epoch 10 : 3688 / 4000 (92.2%)\n",
            "Epoch 11 : 3685 / 4000 (92.125%)\n",
            "Epoch 12 : 3688 / 4000 (92.2%)\n",
            "Epoch 13 : 3694 / 4000 (92.35%)\n",
            "Epoch 14 : 3698 / 4000 (92.45%)\n",
            "Epoch 15 : 3711 / 4000 (92.775%)\n",
            "Epoch 16 : 3705 / 4000 (92.625%)\n",
            "Epoch 17 : 3707 / 4000 (92.675%)\n",
            "Epoch 18 : 3708 / 4000 (92.7%)\n",
            "Epoch 19 : 3708 / 4000 (92.7%)\n",
            "Epoch 20 : 3713 / 4000 (92.825%)\n",
            "Epoch 21 : 3711 / 4000 (92.775%)\n",
            "Epoch 22 : 3716 / 4000 (92.9%)\n",
            "Epoch 23 : 3718 / 4000 (92.95%)\n",
            "Epoch 24 : 3723 / 4000 (93.075%)\n",
            "Epoch 25 : 3716 / 4000 (92.9%)\n",
            "Epoch 26 : 3723 / 4000 (93.075%)\n",
            "Epoch 27 : 3722 / 4000 (93.05%)\n",
            "Epoch 28 : 3724 / 4000 (93.1%)\n",
            "Epoch 29 : 3717 / 4000 (92.925%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30 Epochs bring a 92% accuracy in new data. This accuracy can be increased by setting randomness of entries in mini_batch. i.e. The mini batchs created were of the same content in every epoch. This can be further enhanced by shuffling the entire data set in every epoch, and creat a new and unique mini-batch contents. To help shuffle, you much join the (X,y) as a list and do the shuffling as follows:\n",
        "\n",
        " - random.shuffle(training_data)\n"
      ],
      "metadata": {
        "id": "4qcUaT6uFVao"
      }
    }
  ]
}